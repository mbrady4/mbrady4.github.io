+++
title = "Convolutional Neural Networks"

date = 2019-10-22T00:00:00
lastmod = 2019-10-22T00:00:00
draft = false
reading_time = false

# Authors
authors = ["Michael W. Brady"]
+++
Convolutional neural networks excel at classification tasks involving images (and increasingly NLP classification tasks). Typically output layers for a CNN are seeking to answer classification or prediction problems. 

A convolution is an operation on two functions that produces a third function, showing how one function modifies the other. Applying a convolution effectively transforms the 'shape' of the input. 

The term "convolution" is often used to refer to both the process of computing the third function and the process of apply it. 

![](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-07-at-4-59-29-pm.png?w=748)

Convolution Neural Networks typically have four main operations:

- Convolution
- Non linearity
- Pooling or sub sampling
- Classification (fully connected layer)

Channels refers to a component of an image. Typically an image has three channels—red, blue, and green. This can be visualized as 3 2D matrices stacked on top of each other

### Convolution

The primary purpose of the convolution step is to extract features from the input image. Convolutions preserve the spatial relationship between image pixels by using small squares of input data. 

The small square matrix which slides over the image matrix is reflected to as a filter (also a kernel or a feature detector). For every position, typically the dot product of the filter and the relevant portion of the image matrix are taken. The output of the dot product then is a component of the output matrix. Computing the dot product is often referred to as the 'convolved feature', 'activation map', or 'feature map'.

![](https://ujwlkarn.files.wordpress.com/2016/07/convolution_schematic.gif?w=268&h=196)

The component values of the filter matrix impact the features extracted. During training, a CNN learns the values of the filters. The more filters we have, the more features will be extracted. The size of the feature map produced by the filter is controlled with three parameters:

- **Depth:** The number of filters used in the convolution operation. In the example at the top of the page, three filters are used thus three distinct feature maps are produced
- **Stride:** Number of pixels we slide the filter matrix over the input matrix. A larger stride produces smaller feature maps.
- **Zero-padding:** Padding the input matrix with zeros around the border allows the filter to be applied to bordering elements of the input image matrix.

### Non Linearity

Since the convolution step is a linear process, but most of the real-world data will contain non-linearities we introduce non-linearity by applying a non-linear operation. 

The most common operation to apply is ReLU. ReLU replaces all negative pixel values in the feature map with zero. 

### Pooling

Pooling (also known as subsampling or downsampling) reduces the dimensionality of each feature map but retains the most important information. There are three common types: max, average, sum (Max is typically the best). 

With max pooling, a window is defined and the largest element in the window is taken and added to a subsampled feature map matrix. 

![](https://ujwlkarn.files.wordpress.com/2016/08/screen-shot-2016-08-10-at-3-38-39-am.png?w=494)

Pooling reduces the spatial size of the feature map helping to reduce computational requirements and avoid overfitting.

### Fully Connected Layer

The fully connected layer is a traditional multi layer perceptron typically with a softmax output layer activation function. The purpose of the fully connected layer is to use the features generated by the prior steps to classify the original input image into various classes based on the training dataset. 

[An Intuitive Explanation of Convolutional Neural Networks](https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/)

### Building Image Datasets Quickly

From Lindy on the [Fast.ai](http://fast.ai) forums: 

    1) Using google-images-download 839
    
    $ pip install google_images_download
    
    Install Chrome and Chromedriver to download images from command line.
    
    I installed these onto my virtual machine by navigating to the respective download pages on my laptop’s Chrome browser, and then copying/pasting the correct wget command into the virtual terminal using Chrome’s CurlWget extension 266.
    
    Now I can download. The following gets me 500 medium-sized images of baseball games:
    
    $ googleimagesdownload -k "baseball game" -s medium -l 500 -o fastai/courses/dl1/data/baseballcricket -i train/baseball -cd ~/chromedriver
    
    Experimentally, requesting 500 images worked fine and requesting 4000 cut me off at 450. So to get thousands of images I run the command a few times, changing the date range for each request:
    
    $ googleimagesdownload -k "baseball game" -s medium -wr '{"time_min":"09/01/2018","time_max":"09/30/2018"}' -l 500 -o fastai/courses/dl1/data/baseballcricket -i train/baseball -cd ~/chromedriver

Note, you will need to download and retrieve the file path to [chromedriver](https://sites.google.com/a/chromium.org/chromedriver/downloads) (be sure to download the version that matches your locally installed Chrome browser). 

It likely makes sense to put each class of images into its own folder.